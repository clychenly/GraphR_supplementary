<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>A Methodology | Supplementary Materials for Probabilistic Graphical Modeling under Heterogeneity</title>
  <meta name="description" content="This containes all the supplementary materials for the paper named Probabilistic Graphical Modeling under Heterogeneity." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="A Methodology | Supplementary Materials for Probabilistic Graphical Modeling under Heterogeneity" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This containes all the supplementary materials for the paper named Probabilistic Graphical Modeling under Heterogeneity." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Methodology | Supplementary Materials for Probabilistic Graphical Modeling under Heterogeneity" />
  
  <meta name="twitter:description" content="This containes all the supplementary materials for the paper named Probabilistic Graphical Modeling under Heterogeneity." />
  

<meta name="author" content="Liying Chen^{1,5}, Satwik Acharyya^{1,5}, Chunyu Luo^{2,3}, Yang Ni^4 and Veerabhadran Baladandayuthapani^{1,6}" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="simulation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probabilistic Graphical Model under Heterogeneity</a></li>

<li class="divider"></li>
<li class="appendix"><span><b>Supplementary Materials</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="A" data-path="method.html"><a href="method.html"><i class="fa fa-check"></i><b>A</b> Methodology</a>
<ul>
<li class="chapter" data-level="A.1" data-path="method.html"><a href="method.html#GraphRmodel"><i class="fa fa-check"></i><b>A.1</b> Model and priors</a></li>
<li class="chapter" data-level="A.2" data-path="method.html"><a href="method.html#MFVB"><i class="fa fa-check"></i><b>A.2</b> Mean field variational Bayes</a></li>
<li class="chapter" data-level="A.3" data-path="method.html"><a href="method.html#derivation"><i class="fa fa-check"></i><b>A.3</b> Update equations</a></li>
<li class="chapter" data-level="A.4" data-path="method.html"><a href="method.html#GraphElbo"><i class="fa fa-check"></i><b>A.4</b> Evidence lower bound (ELBO)</a></li>
<li class="chapter" data-level="A.5" data-path="method.html"><a href="method.html#algorithm"><i class="fa fa-check"></i><b>A.5</b> Algorithm</a></li>
<li class="chapter" data-level="A.6" data-path="method.html"><a href="method.html#GraphRcompare"><i class="fa fa-check"></i><b>A.6</b> Overview of competing methods</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>B</b> Simulation studies</a>
<ul>
<li class="chapter" data-level="B.1" data-path="simulation.html"><a href="simulation.html#undir"><i class="fa fa-check"></i><b>B.1</b> Undirected graphical models</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="simulation.html"><a href="simulation.html#simgroupspec"><i class="fa fa-check"></i><b>B.1.1</b> Group specific cases</a></li>
<li class="chapter" data-level="B.1.2" data-path="simulation.html"><a href="simulation.html#simcont"><i class="fa fa-check"></i><b>B.1.2</b> Individual-specific cases</a></li>
<li class="chapter" data-level="B.1.3" data-path="simulation.html"><a href="simulation.html#simhomo"><i class="fa fa-check"></i><b>B.1.3</b> Homogeneous cases</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="simulation.html"><a href="simulation.html#dir"><i class="fa fa-check"></i><b>B.2</b> Directed acyclic graphs (DAGs)</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="simulation.html"><a href="simulation.html#moderate"><i class="fa fa-check"></i><b>B.2.1</b> Moderate dimensions</a></li>
<li class="chapter" data-level="B.2.2" data-path="simulation.html"><a href="simulation.html#largep"><i class="fa fa-check"></i><b>B.2.2</b> Large number of nodes</a></li>
<li class="chapter" data-level="B.2.3" data-path="simulation.html"><a href="simulation.html#largeq"><i class="fa fa-check"></i><b>B.2.3</b> Large number of external covariates</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="simulation.html"><a href="simulation.html#simpson"><i class="fa fa-check"></i><b>B.3</b> Illustration of Simpson’s paradox</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="PAM50.html"><a href="PAM50.html"><i class="fa fa-check"></i><b>C</b> PAM50 proteomics dataset</a>
<ul>
<li class="chapter" data-level="C.1" data-path="PAM50.html"><a href="PAM50.html#PAM50data"><i class="fa fa-check"></i><b>C.1</b> Data description</a></li>
<li class="chapter" data-level="C.2" data-path="PAM50.html"><a href="PAM50.html#PAM50process"><i class="fa fa-check"></i><b>C.2</b> Preprocessing and application</a></li>
<li class="chapter" data-level="C.3" data-path="PAM50.html"><a href="PAM50.html#PAM50result"><i class="fa fa-check"></i><b>C.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="StemnessBC.html"><a href="StemnessBC.html"><i class="fa fa-check"></i><b>D</b> Stemness-induced proteomics dataset</a>
<ul>
<li class="chapter" data-level="D.1" data-path="StemnessBC.html"><a href="StemnessBC.html#StemnessBCdata"><i class="fa fa-check"></i><b>D.1</b> Data description</a></li>
<li class="chapter" data-level="D.2" data-path="StemnessBC.html"><a href="StemnessBC.html#StemnessBCprocess"><i class="fa fa-check"></i><b>D.2</b> Preprocessing and application</a></li>
<li class="chapter" data-level="D.3" data-path="StemnessBC.html"><a href="StemnessBC.html#StemnessBCresult"><i class="fa fa-check"></i><b>D.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="Gyne.html"><a href="Gyne.html"><i class="fa fa-check"></i><b>E</b> Gynecological and breast cancers data</a>
<ul>
<li class="chapter" data-level="E.1" data-path="Gyne.html"><a href="Gyne.html#Gynedata"><i class="fa fa-check"></i><b>E.1</b> Data description</a></li>
<li class="chapter" data-level="E.2" data-path="Gyne.html"><a href="Gyne.html#Gyneprocess"><i class="fa fa-check"></i><b>E.2</b> Preprocessing and application</a></li>
<li class="chapter" data-level="E.3" data-path="Gyne.html"><a href="Gyne.html#Gyneresult"><i class="fa fa-check"></i><b>E.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="ST.html"><a href="ST.html"><i class="fa fa-check"></i><b>F</b> Spatial transcriptomics dataset</a>
<ul>
<li class="chapter" data-level="F.1" data-path="ST.html"><a href="ST.html#STdata"><i class="fa fa-check"></i><b>F.1</b> Data description</a></li>
<li class="chapter" data-level="F.2" data-path="ST.html"><a href="ST.html#STprocess"><i class="fa fa-check"></i><b>F.2</b> Preprocessing and application</a></li>
<li class="chapter" data-level="F.3" data-path="ST.html"><a href="ST.html#STBCresult"><i class="fa fa-check"></i><b>F.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html"><i class="fa fa-check"></i><b>G</b> Implementation</a>
<ul>
<li class="chapter" data-level="G.1" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#GraphRpackage"><i class="fa fa-check"></i><b>G.1</b> GraphR package</a>
<ul>
<li class="chapter" data-level="G.1.1" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#installation"><i class="fa fa-check"></i><b>G.1.1</b> Installation</a></li>
<li class="chapter" data-level="G.1.2" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#graphr_est-function"><i class="fa fa-check"></i><b>G.1.2</b> GraphR_est() function</a></li>
<li class="chapter" data-level="G.1.3" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#graphr_pred-function"><i class="fa fa-check"></i><b>G.1.3</b> GraphR_pred() function</a></li>
<li class="chapter" data-level="G.1.4" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#graphr_visualization-function"><i class="fa fa-check"></i><b>G.1.4</b> GraphR_visualization() function</a></li>
</ul></li>
<li class="chapter" data-level="G.2" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#example"><i class="fa fa-check"></i><b>G.2</b> Example</a>
<ul>
<li class="chapter" data-level="G.2.1" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#example-1"><i class="fa fa-check"></i><b>G.2.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="G.3" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#GraphRshinyApp"><i class="fa fa-check"></i><b>G.3</b> GraphR Shiny App and tutorial website</a></li>
<li class="chapter" data-level="G.4" data-path="ImplementGraphR.html"><a href="ImplementGraphR.html#checkmarks"><i class="fa fa-check"></i><b>G.4</b> Checkmarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supplementary Materials for Probabilistic Graphical Modeling under Heterogeneity</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="method" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">A</span> Methodology<a href="method.html#method" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this Section, we discuss the GraphR model and priors in Section <a href="method.html#GraphRmodel">A.1</a> and brief introduction to variational Bayes inference method with mean-field assumption in Section <a href="method.html#MFVB">A.2</a> followed by detailed derivation of the update equations and evidence lower bound (ELBO) for our GraphR model in Section <a href="method.html#derivation">A.3</a> and Section <a href="method.html#GraphElbo">A.4</a> respectively. In Section <a href="method.html#GraphRcompare">A.6</a>, we provide a comprehensive overview of the GraphR and competing methods.</p>
<p>For notational purposes, we consider <span class="math inline">\(\mathbf{Y} = (Y_1,...,Y_p) \in \mathbb{R}^ {N \times p} \sim \mathcal{N}(\mu,\Omega^{-1}(\mathbf{X}))\)</span>, where the precision matrix <span class="math inline">\(\Omega(\mathbf{X}) = [\omega_{ij}(\mathbf{X})]_{p \times p}\)</span> is a function of external covariates <span class="math inline">\(\mathbf{X} = (X_1,...,X_q) \in \mathbb{R}^ {N \times q}\)</span> and denote <span class="math inline">\(\boldsymbol{\theta}\)</span> as the parameters of estimation. Here <span class="math inline">\(N\)</span>, <span class="math inline">\(p\)</span>, <span class="math inline">\(q\)</span> denotes sample size, number of features and covariates respectively.</p>
<!-- Observed features are denoted as $\mathbf{Y} = (Y_1,...,Y_p)$ and external covariates are $\mathbf{X}  = (X_1,...,X_q)$. We mention the details about the GraphR model in Section \@ref(GraphRmodel) followed by derivations of update equations and ELBO in Section \@ref(derivation) and Section \@ref(GraphElbo) respectively.   -->
<div id="GraphRmodel" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">A.1</span> Model and priors<a href="method.html#GraphRmodel" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The GraphR model is expressed as follows:
<span class="math display" id="eq:graph-reg">\[\begin{equation}
\begin{split}
&amp;   Y_i = \sum_{j \neq i}^p \gamma_{ij}(\mathbf{X}) \odot Y_j + \epsilon_i, \hspace{0.5cm}  \epsilon_i \sim N(0,\frac{1}{\omega_{ii}}), \\
&amp; \gamma_{ij}(X) = -\frac{\omega_{ij}(\mathbf{X})}{\omega_{ii}} =
    -\frac{1}{\omega_{ii}} \mathbf{X} \boldsymbol{\beta_{ij}} =
    -\frac{1}{\omega_{ii}}
    \left(\sum_{l=1}^q \beta_{ijl}X_l \right)
\end{split}
\tag{A.1}
\end{equation}\]</span>
where <span class="math inline">\(\odot\)</span> represents the element-wise multiplication between vectors.</p>
<!-- We further denote parameter $\gamma_{ij}(X)$ as: -->
<!-- \begin{align}\label{eq:CIF} -->
<!--     \gamma_{ij}(X) = -\frac{\omega_{ij}(\mathbf{X})}{\omega_{ii}} =  -->
<!--     -\frac{1}{\omega_{ii}} \mathbf{X} \boldsymbol{\beta_{ij}} =  -->
<!--     -\frac{1}{\omega_{ii}}  -->
<!--     \left(\sum_{l=1}^q \beta_{ijl}X_l \right) -->
<!-- \end{align} -->
<p>Priors on the GraphR model are given below:
<span class="math display" id="eq:spike-slab">\[\begin{align}
\begin{split}
&amp;  \beta_{ijl} = b_{ijl} s_{ijl}, \\
&amp;  b_{ijl} \mid \tau_{il} \sim N (0,\tau_{il}^{-1}), \\
&amp;  s_{ijl} \mid \pi_{ijl} \sim \text{Ber}(\pi_{ijl}), \\
&amp;    \tau_{il} \sim \text{Gamma}(a_\tau,b_\tau) \\
&amp;    \pi_{ijl} \sim \text{Beta}(a_\pi,b_\pi) \\
&amp; \omega_{ii} \propto 1. \\
\end{split}
\tag{A.2}
\end{align}\]</span></p>
<p>Parameters of estimation are <span class="math inline">\(\boldsymbol{\theta} = \{ \boldsymbol{b,s,\omega,\pi,\tau}\}\)</span>.</p>
</div>
<div id="MFVB" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">A.2</span> Mean field variational Bayes<a href="method.html#MFVB" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Varitional Bayes method aims to obtain the optimal approximation of true posterior distribution from a class of tractable distributions <span class="math inline">\(Q\)</span>, called variational family, by minimizing the Kullback-Leibler (KL) divergence between the approximate <span class="math inline">\(q_{\text{vb}}(\boldsymbol{\theta})\)</span> and the true posterior distribution <span class="math inline">\(p(\boldsymbol{\theta|\mathbf{Y,X}})\)</span> <span class="citation">(<a href="#ref-attias2000speech">Attias et al. 2000</a>)</span>. A common choice of <span class="math inline">\(Q\)</span>, known as mean-field approximation, assumes that <span class="math inline">\(q_{\text{vb}}(\boldsymbol{\theta})\)</span> can be expressed as <span class="math inline">\(\prod_{k=1}^K q^k_{\text{vb}}(\boldsymbol{\theta_k})\)</span> for some partition of <span class="math inline">\(\boldsymbol{\theta}\)</span>. One can write <span class="math inline">\(q_{\text{vb}}(\boldsymbol{\theta})\)</span> as</p>
<p><span class="math display">\[\begin{align}\label{eq:KL_div}
    &amp; q_{\text{vb}}^{*}(\boldsymbol{\theta}) \in \text{arg} \underset{q_{\text{vb}}(\boldsymbol{\theta}) \in \mathbb{Q}}{\text{min}} \ KL(q_{\text{vb}}(\boldsymbol{\theta})\|p(\boldsymbol{\theta |Y,X})) \text{, where} \nonumber \\
    &amp; KL(q_{\text{vb}}(\boldsymbol{\theta})\|p(\boldsymbol{\theta|Y,X})) = \int q_{\text{vb}}(\boldsymbol{\theta}) \text{ log} \left (\frac{q_{\text{vb}}(\boldsymbol{\theta})}{p(\boldsymbol{\theta|Y,X})}\right)d\boldsymbol{\theta} \nonumber \\
    &amp; = - \int q_{\text{vb}}(\boldsymbol{\theta}) \text{ log} \left (\frac{p(\boldsymbol{\theta|Y,X})}{q_{\text{vb}}(\boldsymbol{\theta})}\right)d\boldsymbol{\theta}
     = - \int q_{\text{vb}}(\boldsymbol{\theta}) \text{ log} \left (\frac{p(\boldsymbol{\theta,Y,X})}{q_{\text{vb}}(\boldsymbol{\theta})}\right)d\boldsymbol{\theta} + \text{ log} \left[ p(\boldsymbol{Y,X}) \right].
\end{align}\]</span></p>
<p>We denote <span class="math inline">\(L[q_{\text{vb}}(\boldsymbol{\theta})] = \int q_{\text{vb}}(\boldsymbol{\theta}) \text{log} \left ( p(\boldsymbol{\theta,Y,X}) / q_{\text{vb}}(\boldsymbol{\theta}) \right)d\boldsymbol{\theta}\)</span> which is the lower bound of the model log-likelihood, and write <span class="math inline">\(KL(q_{\text{vb}}(\boldsymbol{\theta})\|p(\boldsymbol{\theta|Y,X})) = -L[q_{\text{vb}}(\boldsymbol{\theta})] + \text{ log} \left[ p(\boldsymbol{Y,X}) \right]\)</span>. Minimizing KL-divergence is equivalent to maximizing <span class="math inline">\(L[q_{\text{vb}}(\boldsymbol{\theta})]\)</span> since <span class="math inline">\(\text{ log} \left[ p(\boldsymbol{Y,X}) \right]\)</span> doesn’t involve <span class="math inline">\(\boldsymbol{\theta}\)</span>. We can further show that
<span class="math display">\[\begin{align}\label{eq:lowerbound}
L[q_{\text{vb}}(\boldsymbol{\theta})] &amp;= \int q_{\text{vb}}(\boldsymbol{\theta}) \left[ \text{ log }p(\boldsymbol{\theta,Y,X}) - \text{ log } q_{\text{vb}}(\boldsymbol{\theta}) \right] d\boldsymbol{\theta} \nonumber \\
&amp; = \int q^{k}_{\text{vb}}(\boldsymbol{\theta_k})
\int \left[
\left(\text{ log }p(\boldsymbol{\theta,Y,X}) - \text{ log }q_{\text{vb}}(\boldsymbol{\theta_k})
\right) \right] \prod_{i \neq k} q_{\text{vb}}(\boldsymbol{\theta_i}) d\boldsymbol{\theta_{-k}}d\boldsymbol{\theta_k}  
\nonumber \\
&amp; \text{  } -\int \sum_{i \neq k} \text{ log }q_{\text{vb}}(\boldsymbol{\theta_i}) \prod_{i \neq k} q_{\text{vb}}(\boldsymbol{\theta_i}) \int q_{\text{vb}}(\boldsymbol{\theta_k}) d\boldsymbol{\theta_{-k}}d\boldsymbol{\theta_k}
\nonumber \\
&amp;= \int q^{k}_{\text{vb}}(\boldsymbol{\theta_k})
\left[\mathbb{E}_{-k} (\text{ log }p(\boldsymbol{\theta,Y,X})) -
\text{ log } q_{\text{vb}}(\boldsymbol{\theta_k})\right]
d\boldsymbol{\theta_k} - \text{const}  \nonumber \\
&amp;=-KL(q^{k}_{\text{vb}}(\boldsymbol{\theta_k}) \| \text{ exp } \left[
\mathbb{E}_{-k} (\text{ log }p(\boldsymbol{\theta,Y,X}))
\right]).
\end{align}\]</span></p>
<p>Therefore, we have <span class="math inline">\(q^{k}_{\text{vb}}(\boldsymbol{\theta_k}) \propto \text{ exp } \left[ \mathbb{E}_{-k} (\text{ log }p(\boldsymbol{\theta,Y,X})) \right]\)</span>.</p>
<!-- ## Method details {#GraphRmethod} -->
<!-- Observed features are denoted as $\mathbf{Y} = (Y_1,...,Y_p)$ and external covariates are $\mathbf{X}  = (X_1,...,X_q)$. We mention the details about the GraphR model in Section \@ref(GraphRmodel) followed by derivations of update equations and ELBO in Section \@ref(derivation) and Section \@ref(GraphElbo) respectively.   -->
<!-- ### Model and priors {#GraphRmodel} -->
<!-- The GraphR model is expressed as follows:  -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- &   Y_i = \sum_{j \neq i}^p \gamma_{ij}(\mathbf{X}) \odot Y_j + \epsilon_i, \hspace{0.5cm}  \epsilon_i \sim N(0,\frac{1}{\omega_{ii}}), \\ -->
<!-- & \gamma_{ij}(X) = -\frac{\omega_{ij}(\mathbf{X})}{\omega_{ii}} =  -->
<!--     -\frac{1}{\omega_{ii}} \mathbf{X} \boldsymbol{\beta_{ij}} =  -->
<!--     -\frac{1}{\omega_{ii}}  -->
<!--     \left(\sum_{l=1}^q \beta_{ijl}X_l \right) -->
<!-- \end{split} -->
<!-- (\#eq:graph-reg) -->
<!-- \end{equation} -->
<!-- where $\odot$ represents the element-wise multiplication between vectors. -->
<!-- <!-- We further denote parameter $\gamma_{ij}(X)$ as: -->
<!-- <!-- \begin{align}\label{eq:CIF} -->
<!-- <!--     \gamma_{ij}(X) = -\frac{\omega_{ij}(\mathbf{X})}{\omega_{ii}} =  -->
<!-- <!--     -\frac{1}{\omega_{ii}} \mathbf{X} \boldsymbol{\beta_{ij}} =  -->
<!-- <!--     -\frac{1}{\omega_{ii}}  -->
<!-- <!--     \left(\sum_{l=1}^q \beta_{ijl}X_l \right) -->
<!-- <!-- \end{align} -->
<!-- Priors on the GraphR model are given below: -->
<!-- \begin{align} -->
<!-- \begin{split} -->
<!-- &  \beta_{ijl} = b_{ijl} s_{ijl}, \\ -->
<!-- &  b_{ijl} \mid \tau_{il} \sim N (0,\tau_{il}^{-1}), \\ -->
<!-- &  s_{ijl} \mid \pi_{ijl} \sim \text{Ber}(\pi_{ijl}), \\ -->
<!-- &    \tau_{il} \sim \text{Gamma}(a_\tau,b_\tau) \\ -->
<!-- &    \pi_{ijl} \sim \text{Beta}(a_\pi,b_\pi) \\ -->
<!-- & \omega_{ii} \propto 1. \\ -->
<!-- \end{split} -->
<!-- (\#eq:spike-slab) -->
<!-- \end{align} -->
<!-- Parameters of estimation are $\boldsymbol{\theta} = \{ \boldsymbol{b,s,\omega,\pi,\tau}\}$. -->
</div>
<div id="derivation" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">A.3</span> Update equations<a href="method.html#derivation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The likelihood is expressed as
<span class="math display">\[\begin{align}
    p(\boldsymbol{\theta,Y,X}) &amp;\propto \prod_{i=1}^p
    \left\{
    \left|
    \frac{1}{\omega_{ii}}I_n
    \right|^{-\frac{1}{2}} \text{exp}
    \left[ -\frac{\omega_{ii}}{2}
    \left\| Y_i - \sum_{j \neq i} \gamma_{ij}(X) \odot Y_j
    \right \|^2
    \right]
    \right\} \times \nonumber \\
    &amp; \prod_{i=1}^p \prod_{j \neq i}^p \prod_{l=1}^q \left\{\left(\frac{1}{\tau_{il}}\right)^{-\frac{1}{2}}
    \text{exp} \left[-\frac{\tau_{il}}{2}(b_{ijl})^2 \right] \left(\pi_{ijl}\right)^{s_{ijl}}
    \left(1-\pi_{ijl}\right)^{1-s_{ijl}}
    \right\} \times
    \nonumber \\
    &amp;\prod_{i=1}^p \prod_{l=1}^q
    \left\{
    \left(\tau_{il}
    \right) ^ {a_\tau-1}
    \text{exp}\left[
    -b_\tau \tau_{il}
    \right]
    \right\} \times
    \nonumber \\
    &amp;\prod_{i=1}^p \prod_{j \neq i}^p \prod_{l=1}^q\left\{
    \left(\pi_{ijl}\right)^{a_\pi-1}
    \left(1-\pi_{ijl}\right)^{b_\pi-1}
    \right\}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
    \text{log} p(\boldsymbol{\theta,Y,X}) = &amp;\text{Const}+
    \sum_{i=1}^p \left\{ \frac{n}{2} \text{log}(\omega_{ii}) - \frac{\omega_{ii}}{2} \left\| Y_i + \frac{1}{\omega_{ii}} \sum_{j \neq i}^p \sum_{l=1}^q b_{ijl} s_{ijl} X_l \odot Y_j \right \|^2
    \right\} \nonumber \\
    &amp;+ \sum_{i=1}^p \sum_{l=1}^q
    \left\{
    \left(
    \frac{p-1}{2} + a_\tau-1
    \right) \text{log}(\tau_{il}) -
    \left(
    b_\tau + \frac{1}{2}\sum_{j \neq i}^p
    \left(
    b_{ijl}
    \right)^2
    \right) \tau_{il}
    \right\} \nonumber \\
    &amp;+ \sum_{i=1}^p \sum_{j \neq i}^p \sum_{l=1}^q
    \left\{
    \left(
    s_{ijl} + a_\pi -1
    \right)\text{log}(\pi_{ijl}) +
    \left(
    b_\pi-s_{ijl}
    \right)
    \text{log}(1-\pi_{ijl})
    \right\}.
\end{align}\]</span></p>
<p>Due to the dependence between <span class="math inline">\(\boldsymbol{b}\)</span> and <span class="math inline">\(\boldsymbol{s}\)</span> <span class="citation">(<a href="#ref-titsias2011spike">Titsias and Lázaro-Gredilla 2011</a>)</span>, the mean-field assumption is considered as:
<span class="math display">\[q_{\text{vb}}(\boldsymbol{b,s,\omega,\pi,\tau}) = q_{\text{vb}}(\boldsymbol{b,s})q_{\text{vb}}(\boldsymbol{\omega})q_{\text{vb}}(\boldsymbol{\pi})q_{\text{vb}}(\boldsymbol{\tau}).\]</span></p>
<p>We can obtain the update equation for each parameter as <span class="math inline">\(q^{k}_{\text{vb}}(\boldsymbol{\theta_k}) \propto \text{ exp } \left[ \mathbb{E}_{-k} (\text{ log }p(\boldsymbol{\theta,Y,X})) \right]\)</span>.</p>
<!-- Based on the results that $q_k(\boldsymbol{\theta_k}) \propto \text{ exp } \left[ -->
<!-- \mathbb{E}_{-k} (\text{ log }p(\boldsymbol{\theta,Y,X})) -->
<!-- \right]$, we can update the parameters as following: -->
<p><strong>a. Update of</strong> <span class="math inline">\(\tau_{il}\)</span>:
<span class="math display">\[\begin{align}
    \text{log} \ q_{\text{vb}}(\tau_{il}) &amp;= \mathbb{E}_{-\tau_{il}} (l) \nonumber\\
    &amp;= C +
    \left[
    \frac{p-1}{2}+a_\tau-1
    \right] \text{log} \tau_{il} +
    \left[
    b_\tau + \frac{1}{2}\sum_{j \neq i}^p
    \mathbb{E}_{-\tau_{il}}
    \left(
    b_{ijl}
    \right)^2
    \right] \tau_{il}.
\end{align}\]</span></p>
<!-- Thus, we have $$q(\tau_{il}) \sim \Gamma \left(a_\tau + \frac{p-1}{2}, b_\tau + \frac{1}{2}\sum_{j \neq i}^p -->
<!--     \mathbb{E}_{-\tau_{il}}\left( -->
<!--     b_{ijl} -->
<!--     \right)^2 -->
<!--     \right)$$ -->
<!-- :::: {.bluebox data-latex=""} -->
<p><span class="math display">\[q_{\text{vb}}(\tau_{il}) \sim \Gamma \left(a_\tau + \frac{p-1}{2}, b_\tau + \frac{1}{2}\sum_{j \neq i}^p
    \mathbb{E}_{-\tau_{il}}\left(
    b_{ijl}
    \right)^2
    \right)\]</span>
<!-- :::: --></p>
<p><br />
<strong>b. Update of</strong> <span class="math inline">\(\pi_{ijl}\)</span>:
<span class="math display">\[\begin{align}
    \text{log} \ q_{\text{vb}}(\pi_{ijl})
    &amp;= \mathbb{E}_{-\pi_{ijl}} (l) \nonumber \\
    &amp;= C+
    \left[
    \mathbb{E}_{-\pi_{ijl}}(s_{ijl})+a_\pi-1
    \right] \text{log}(\pi_{ijl}) +
    \left[
    b_\pi - \mathbb{E}_{-\pi_{ijl}}(s_{ijl})
    \right] \text{log}(1-\pi_{ijl}).
\end{align}\]</span></p>
<!-- :::: {.bluebox data-latex=""} -->
<p><span class="math display">\[q_{\text{vb}}(\pi_{ijl}) \sim \text{Beta} \left(\mathbb{E}_{-\pi_{ijl}}(s_{ijl})+a_\pi, b_\pi - \mathbb{E}_{-\pi_{ijl}}(s_{ijl}) +1 \right)\]</span>
<!-- :::: --></p>
<p><br />
<strong>c. Update</strong> <span class="math inline">\(\omega_{ii}\)</span>:
<span class="math display">\[\begin{align}
\text{log} \ q_{\text{vb}}(\omega_{ii})
&amp;= \mathbb{E}_{-\omega_{ii}}(l) \nonumber \\
&amp;= C+
\frac{n}{2} \text{log}(\omega_{ii}) -\frac{\|Y_i\|^2}{2} \omega_{ii} - \frac{\mathbb{E}_{-\omega_{ii}}\|\sum_{j \neq i}^p \sum_{s=1}^q b_{ijl}s_{ijl}
X_l \odot Y_j\|^2}{2} \left( \frac{1}{\omega_{ii}} \right).
\end{align}\]</span></p>
<!-- :::: {.bluebox data-latex=""} -->
<p><span class="math display">\[q_{\text{vb}}(\omega_{ii}) \sim \text{GIG} \left(\frac{n+2}{2},\|Y_i\|^2,
\mathbb{E}_{-\omega_{ii}}\|\sum_{j \neq i}^p \sum_{s=1}^q b_{ijl}s_{ijl}
X_l \odot Y_j\|^2 \right)\]</span>
<!-- :::: -->
Here <strong>GIG</strong> represents generalized inverse Gaussian distribution.</p>
<p><strong>d. Update</strong> <span class="math inline">\(\beta_{ijl} = b_{ijl}s_{ijl}\)</span>:</p>
<p><span class="math inline">\(\text{We Denote } M_{-(m,n)}^{-k} = \sum_{j \neq m }^p \sum_{s=1 }^q b_{mj}^s s_{mj}^s X_s \odot Y_j - b_{mn}^{(k)} s_{mn}^{(k)} X_k \odot Y_n\)</span> and
<span class="math display">\[\begin{align}
\text{log} \ q_{\text{vb}}(b_{ijl}|s_{ijl})
&amp;= \mathbb{E}_{-b_{ijl}|s_{ijl}}(l) \nonumber \\
&amp;= C-\frac{1}{2}
\left[
\mathbb{E}_{-b_{ijl}|s_{ijl}}(\tau_{il}) + \mathbb{E}_{-b_{ijl}|s_{ijl}} \left( \frac{1}{\omega_{ii}} \right) s_{ijl} \|X_l \odot Y_j \|^2
\right]
\left(b_{ijl}
\right)^2 \nonumber \\
&amp;-\left[Y_i+\mathbb{E}_{-b_{ijl}|s_{ijl}} \left( \frac{1}{\omega_{ii}} \right)\mathbb{E}_{-b_{ijl}|s_{ijl}}M_{-(i,j)}^{-s}
\right]^T
\left[X_l \odot Y_j
\right] s_{ijl} b_{ijl}.
\end{align}\]</span></p>
<!-- Denote: -->
<!-- $$\sigma^2(s_{ijl}) = \left[ -->
<!-- \mathbb{E}_{-b_{ijl}|s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 s_{ijl} + \mathbb{E}_{-b_{ijl}|s_{ijl}}(\tau_{il}) \right]^{-1}$$ -->
<!-- $$\mu(s_{ijl}) = - \sigma^2(s_{ijl}) -->
<!-- \left\{ -->
<!-- \left[Y_i + \mathbb{E}_{-b_{ijl}|s_{ijl}} -->
<!-- \left(\frac{1}{\omega_{ii}} M_{-(i,j)}^s -->
<!-- \right) -->
<!-- \right]^T -->
<!-- [Z_s \odot Y_j]  s_{ijl} -->
<!-- \right\}$$ -->
<!-- Thus, we have $$q(b_{ijl}|s_{ijl}) \sim \mathbb{N} \left(\mu(s_{ijl}),\sigma^2(s_{ijl})\right)$$ -->
<!-- :::: {.bluebox data-latex=""} -->
<p><span class="math display">\[q_{\text{vb}}(b_{ijl}|s_{ijl}) \sim \mathbb{N} \left(\mu(s_{ijl}),\sigma^2(s_{ijl})\right)\]</span>
<span class="math display">\[\sigma^2(s_{ijl}) = \left[
\mathbb{E}_{-b_{ijl}|s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 s_{ijl} + \mathbb{E}_{-b_{ijl}|s_{ijl}}(\tau_{il}) \right]^{-1}\]</span></p>
<p><span class="math display">\[\mu(s_{ijl}) = - \sigma^2(s_{ijl})
\left\{
\left[Y_i + \mathbb{E}_{-b_{ijl}|s_{ijl}}
\left(\frac{1}{\omega_{ii}} M_{-(i,j)}^{-s}
\right)
\right]^T
[Z_s \odot Y_j]  s_{ijl}
\right\}\]</span>
<!-- :::: --></p>
<p><br />
The mariginal density of <span class="math inline">\(q_{\text{vb}}(s_{ijl})\)</span> is obtained by integrating the joint density of <span class="math inline">\(q_{\text{vb}}(b_{ijl},s_{ijl})\)</span> as
<span class="math display">\[\begin{align*}
\begin{split}
&amp; q_{\text{vb}}(s_{ijl}) = \int \text{exp} \left\{ \text{log} \ q_{\text{vb}}(b_{ijl},s_{ijl}) \right\}db_{ijl} \\
&amp; = \text{exp} \left\{
    s_{ijl} \ \mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl})\right\}\ \int \mathbb{N}_{b_{ijl}}
    \left(\mu(s_{ijl}),\sigma^2(s_{ijl})\right) \sigma(s_{ijl})
    \text{exp } \left(
    \frac{\mu^2(s_{ijl})}{2\sigma^2(s_{ijl})}\right) db_{ijl} \\
&amp; = \sigma(s_{ijl})
    \text{exp} \left\{
    s_{ijl} \ \mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl}) + \left(
    \frac{\mu^2(s_{ijl})}{2\sigma^2(s_{ijl})}\right)
    \right\}. \\
&amp; \text{log} [q_{\text{vb}}(s_{ijl})] =
    C + \text{log}(\sigma(s_{ijl})) +
    s_{ijl} \ \mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl}) +
    \frac{\mu^2(s_{ijl})}{2\sigma^2(s_{ijl})}  \\    
&amp; \text{log} [q_{\text{vb}}(s_{ijl}=0)] = C - \frac{1}{2} \text{log} \mathbb{E}_{-s_{ijl}}\tau_{ijl} \\
&amp; \text{log} [q_{\text{vb}}(s_{ijl}=1)] = C +\mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl})
- \frac{1}{2} \text{log} \left[\mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right] \\
&amp; + \frac{1}{2}\left[\mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right]^{-1}\left[(X_l \odot Y_j)^T (Y_i + \mathbb{E}_{-s_{ijl}} \left(\frac{1}{\omega_{ii}}\right) \mathbb{E}_{-s_{ijl}} M_{-(i,j)}^{-s}) \right]^2
\end{split}
\end{align*}\]</span></p>
<!-- :::: {.bluebox data-latex=""} -->
<p><span class="math display">\[\begin{equation*}
\begin{split}
&amp; s_{ijl} \sim \text{Ber}(\psi_{ijl}) \\
&amp; \text{log} \ q_{\text{vb}}(s_{ijl}) = C + s_{ijl}\text{logit}(\psi_{ijl}) \\
&amp; \psi_{ijl} = \mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl}) - \frac{1}{2}log\left[
\mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right] + \frac{1}{2}log \mathbb{E}_{-s_{ijl}} \tau_{il} \\
&amp;+ \frac{1}{2}\left[
\mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right]^{-1}\left[
(X_l \odot Y_j)^T (Y_i + \mathbb{E}_{-s_{ijl}}\left[\frac{1}{\omega_{ii}}\right] \mathbb{E}_{-s_{ijl}} M_{-(i,j)}^{-s})
\right]^2 \\
\end{split}
\end{equation*}\]</span>
<!-- ::::  --></p>
<!-- Thus, -->
<!-- \begin{align} -->
<!-- log \ q(s_{ijl}) &= s_{ijl} log\ q(s_{ijl}=1) + (1-s_{ijl}) log\ q(s_{ijl}=0) \nonumber \\ -->
<!-- &= C + s_{ijl} -->
<!-- \{\mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl}) - \frac{1}{2}log\left[ -->
<!-- \mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right] \nonumber \\ -->
<!-- &+ \frac{1}{2}\left[ -->
<!-- \mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right]^{-1}\left[ -->
<!-- (X_l \odot Y_j)^T (Y_i + \mathbb{E}_{-s_{ijl}}\left[\frac{1}{\omega_{ii}}\right] \mathbb{E}_{-s_{ijl}} M_{-(i,j)}^{-s}) -->
<!-- \right]^2 \nonumber \\ -->
<!-- &+ \frac{1}{2}log \mathbb{E}_{-s_{ijl}} \tau_{il}\} -->
<!-- \end{align} -->
</div>
<div id="GraphElbo" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">A.4</span> Evidence lower bound (ELBO)<a href="method.html#GraphElbo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As shown previously, the evidence lower bound is defined as:</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}
L[q_{\text{vb}}(\boldsymbol{\theta})] &amp;= \int q_{\text{vb}}(\boldsymbol{\theta}) \text{log} \left ( p(\boldsymbol{\theta,Y,X}) / q_{\text{vb}}(\boldsymbol{\theta}) \right)d\boldsymbol{\theta} \\
&amp; = \mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})}
\text{ log}(p(\boldsymbol{\theta,Y,X}))
- \mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\boldsymbol{\theta})] \\
&amp; = \mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})}
\text{ log}(p(\boldsymbol{\theta,Y,X}))
- \sum_{i=1}^p \mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\omega_{ii})]
- \sum_{i=1}^p \sum_{l=1}^q \mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\tau_{il})] \\
&amp; - \sum_{i=1}^p \sum_{j \neq i}^p \sum_{l=1}^q
\left\{
\mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(b_{ijl},s_{ijl})] +
\mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\pi_{ijl})]
\right\}.
\end{split}
\end{equation*}\]</span>
Notably, <span class="math inline">\(-\mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\omega_{ii})] , -\mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\tau_{il})], -\mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(b_{ijl},s_{ijl})], -\mathbb{E}_{q_{\text{vb}}(\boldsymbol{\theta})} [q_{\text{vb}}(\pi_{ijl})]\)</span> are entropies of GIG, Gamma, Normal, Bernoulli and Beta distributions, which have a close form. We denote entropy as <span class="math inline">\(H(\cdot)\)</span> and all the expectations below are taken w.r.t <span class="math inline">\(q_{\text{vb}}(\boldsymbol{\theta})\)</span>.</p>
<p><strong>a. Derivation of</strong> <span class="math inline">\(\mathbb{E} \text{ log}(p(\boldsymbol{\theta,Y,X}))\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\begin{split}
\mathbb{E} \text{ log}(p(\boldsymbol{\theta,Y,X}))
= &amp; \sum_{i=1}^p
\biggl \{
-\frac{n + (p-1)q}{2} \text{log} 2\pi
+ q \left[
a_\tau \text{log}b_\tau -  \text{log} \Gamma(a_\tau)
\right]  \\
&amp; + (p-1)q \left[
\text{log} \Gamma(a_\pi + b_\pi)
-\text{log} \Gamma(a_\pi b_\pi)
\right] \\
&amp; + \frac{n}{2} \mathbb{E}(\text{log}\omega_{ii})
-\frac{\|Y_i\|^2}{2} \mathbb{E}\omega_{ii}
-\mathbb{E}(\omega_{ii}^{-1}) \mathbb{E}
\left\|
\sum_{j \neq i}^p \sum_{l=1}^q \beta_{ijl} Z_l \odot Y_j
\right \|^2 \\
&amp; - Y_i^T \left(\sum_{j \neq i}^p \sum_{l=1}^q \mathbb{E} \beta_{ijl} Z_l \odot Y_j
\right) \\
&amp; + \sum_{l=1}^q
\left[
\left(
\frac{p-1}{2} + a_\tau-1
\right) \mathbb{E} \left(\text{log} \tau_{il}
\right) -
\left(
b_\tau + \frac{\sum_{j \neq i}^p \mathbb{E}b_{ijl}^2}{2} \right)  \mathbb{E}
\tau_{il}
\right] \\
&amp; + \sum_{j \neq i}^p \sum_{l=1}^q \left[
\left(
\mathbb{E}s_{ijl}+a_\pi - 1
\right) \mathbb{E} (\text{log} \pi_{ijl}) + (b_\pi - \mathbb{E}s_{ijl})
\right] \mathbb{E} \left(\text{log} (1-\pi_{ijl})
\right)
\biggl \}
\end{split}
\end{align*}\]</span></p>
<p><strong>b. Derivation of</strong> <span class="math inline">\(H(\tau_{il})\)</span>
<span class="math display">\[\begin{align*}
\begin{split}
H(\tau_{il}) = &amp; - \left[a_\tau+\frac{p-1}{2}\right] \text{log}\left[b_\tau + \frac{1}{2}\sum_{j \neq i} ^p\mathbb{E}b_{ijl}^2\right] + \text{log } \Gamma(a_\tau+\frac{p-1}{2}) \\
&amp; - \left[a_\tau+\frac{p-1}{2} -1 \right] \mathbb{E}(\text{log }\tau_{il})
+ \left[b_\tau + \frac{1}{2}\sum_{j \neq i} ^p\mathbb{E}b_{ijl}^2\right] \mathbb{E}\tau_{il}
\end{split}
\end{align*}\]</span></p>
<p><strong>c. Derivation of</strong> <span class="math inline">\(H(\pi_{ijl})\)</span>
<span class="math display">\[\begin{align*}
\begin{split}
H(\pi_{ijl}) =
&amp; - \text{log }\Gamma(a_\pi+b_\pi+1)
+ \text{log }
\Gamma(\mathbb{E}s_{ijl} + a_\pi) + \text{log }
\Gamma(b_\pi + 1 - \mathbb{E}s_{ijl}) \\
&amp; - (\mathbb{E}s_{ijl} + a_\pi -1) \mathbb{E} \text{log } \pi_{ijl}
- (b_\pi - \mathbb{E}s_{ijl}) \mathbb{E} \text{log } (1-\pi_{ijl})
\end{split}
\end{align*}\]</span></p>
<p><strong>d. Derivation of</strong> <span class="math inline">\(H(\omega_{ii})\)</span></p>
<p>Denote <span class="math inline">\(a_{\omega_{ii}} = \|Y_i\|^2\)</span> and <span class="math inline">\(b_{\omega_{ii}} = \mathbb{E}\|\sum_{j \neq i}^p \sum_{l=1}^q \beta_{ijl} Z_l \odot Y_j\|^2\)</span></p>
<p><span class="math display">\[H(\omega_{ii}) = -\frac{n+2}{4} \text{log}\frac{a_{\omega_{ii}}}{b_{\omega_{ii}}} + \text{log}(2K_{(n+2)/2}\sqrt{a_{\omega_{ii}} b_{\omega_{ii}}}) -\frac{n}{2}\mathbb{E}(\text{log}\omega_{ii})+ \frac{a_{\omega_{ii}}}{2}\mathbb{E}\omega_{ii} + \frac{b_{\omega_{ii}}}{2}\mathbb{E}\omega_{ii}^{-1}\]</span></p>
<p><strong>e. Derivation of</strong> <span class="math inline">\(H(b_{ijl}, s_{ijl})\)</span>
<span class="math display">\[H(b_{ijl}, s_{ijl}) = H(b_{ijl}|s_{ijl}) + H(s_{ijl})\]</span>
where
<span class="math display">\[H(b_{ijl}|s_{ijl}) = \frac{1}{2} \text{log} \left[2\pi\sigma^2(s_{ijl})\right] + \frac{1}{2}\]</span></p>
<p><span class="math display">\[H(s_{ijl}) = -\psi_{ijl} \text{ log}(\psi_{ijl}) - (1-\psi_{ijl}) \text{ log}(1-\psi_{ijl})\]</span></p>
<p>Combining all the previous entropy derivations, we have the following expression of evidence lower bound (ELBO) as
$
<span class="math display">\[\begin{align*}
\begin{split}
L[q_{\text{vb}}(\boldsymbol{\theta})] =
&amp; -\frac{np + p(p-1)q}{2} \text{log} 2\pi \\
&amp; + p q \left[
a_\tau \text{log}b_\tau -  \text{log} \Gamma(a_\tau)
+ \text{log} \Gamma(a_\tau + \frac{p-1}{2})
\right]
\\
&amp; + p(p-1)q \left[
\text{log} \Gamma(a_\pi + b_\pi)
-\text{log} \Gamma(a_\pi b_\pi)
-\text{log} \Gamma(a_\pi+b_\pi+1)
\right] \\
&amp; - \sum_{i=1}^p
\left\{
Y_i^T \left(
\sum_{j \neq i}^p \sum_{l=1}^q \mathbb{E} \beta_{ijl} Z_l \odot Y_j
\right)
- \frac{n+2}{4} \text{log}\frac{a_{\omega_{ii}}}{b_{\omega_{ii}}} + \text{log}(2K_{(n+2)/2}\sqrt{a_{\omega_{ii}} b_{\omega_{ii}}})
\right\} \\
&amp;- \left[a_\tau+\frac{p-1}{2}\right]
\sum_{i=1}^p \sum_{l=1}^q
\left\{
\text{log}\left[b_\tau + \frac{1}{2}\sum_{j \neq i} ^p\mathbb{E}b_{ijl}^2\right]
\right \} \\
&amp;+ \sum_{i=1}^p \sum_{j \neq i}^p \sum_{l=1}^q \biggl \{
\text{log }
\Gamma(\mathbb{E}s_{ijl} + a_\pi) + \text{log }
\Gamma(b_\pi + 1 - \mathbb{E}s_{ijl}) \\
&amp;+ \frac{1}{2} \text{log} \left[2\pi\sigma^2(s_{ijl})\right] + \frac{1}{2} -\psi_{ijl} \text{ log}(\psi_{ijl}) - (1-\psi_{ijl}) \text{ log}(1-\psi_{ijl})
\biggl \}.
\end{split}
\end{align*}\]</span></p>
</div>
<div id="algorithm" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">A.5</span> Algorithm<a href="method.html#algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<center>
<img src="images/algorithm.jpg" width="1000" >
</center>
<!-- \begin{algorithm} -->
<!-- \caption{GraphR algorithm}\label{alg:cap} -->
<!-- \begin{algorithmic} -->
<!-- \State \textbf{Input:} $\mathbf{Y,X}, \text{tolerance}$ -->
<!-- \State \textbf{Output:} Covariate dependent edges -->
<!-- \While {$\zeta > \text{tolerance}$} -->
<!-- \For {$i \text{ in } 1:p$} -->
<!--     \For {$l \text{ in } 1:q$} -->
<!--         \State \textbf{Set} $q_{\text{vb}}(\tau_{il}) \sim \Gamma \left(a_\tau + \frac{p-1}{2}, b_\tau + \frac{1}{2}\sum_{j \neq i}^p -->
<!--     \mathbb{E}_{-\tau_{il}}\left( -->
<!--     b_{ijl} -->
<!--     \right)^2 -->
<!--     \right)$ -->
<!--     \EndFor -->
<!--     \For {$j \text{ in } 1:p \text{ and } j \neq i;l \text{ in } 1:q$} -->
<!--     \State \textbf{Set} $q_{\text{vb}}(\pi_{ijl}) \sim \text{Beta} \left(\mathbb{E}_{-\pi_{ijl}}(s_{ijl})+a_\pi, b_\pi - \mathbb{E}_{-\pi_{ijl}}(s_{ijl}) +1 \right)$ -->
<!--     \EndFor -->
<!--     \State \textbf{Set} $q_{\text{vb}}(\omega_{ii}) \sim \text{GIG} \left(\frac{n+2}{2},\|Y_i\|^2, -->
<!-- \mathbb{E}_{-\omega_{ii}}\|\sum_{j \neq i}^p \sum_{s=1}^q b_{ijl}s_{ijl} -->
<!-- X_l \odot Y_j\|^2 \right)$ -->
<!--     \For {$j \text{ in } 1:p \text{ and } j \neq i;l \text{ in } 1:q$} -->
<!--     \State $\beta_{ijl} = b_{ijl}s_{ijl}$ -->
<!--     \State \textbf{Set} $q_{\text{vb}}(b_{ijl}|s_{ijl}) \sim \mathbb{N} \left(\mu(s_{ijl}),\sigma^2(s_{ijl})\right)$ where -->
<!-- \State $\sigma^2(s_{ijl}) = \left[ -->
<!-- \mathbb{E}_{-b_{ijl}|s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 s_{ijl} + \mathbb{E}_{-b_{ijl}|s_{ijl}}(\tau_{il}) \right]^{-1}$ -->
<!-- \State $\mu(s_{ijl}) = - \sigma^2(s_{ijl}) -->
<!-- \left\{ -->
<!-- \left[Y_i + \mathbb{E}_{-b_{ijl}|s_{ijl}} -->
<!-- \left(\frac{1}{\omega_{ii}} M_{-(i,j)}^{-s} -->
<!-- \right) -->
<!-- \right]^T -->
<!-- [Z_s \odot Y_j]  s_{ijl} -->
<!-- \right\}$ -->
<!-- \State \textbf{Set} $q_{vb}(s_{ijl}) \sim \text{Ber}(\psi_{ijl})$ where: -->
<!-- \State $\psi_{ijl} = \mathbb{E}_{-s_{ijl}} \text{logit}(\pi_{ijl}) + \frac{1}{2}log \mathbb{E}_{-s_{ijl}} \tau_{il} - $ -->
<!-- \State $ \frac{1}{2}log\left[ -->
<!-- \mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right]  + $ -->
<!-- \State $\frac{1}{2}\left[ -->
<!-- \mathbb{E}_{-s_{ijl}}(\frac{1}{\omega_{ii}})\|X_l \odot Y_j\|^2 + \mathbb{E}_{-s_{ijl}}(\tau_{il}) \right]^{-1} \times$ -->
<!-- \State $\left[ -->
<!-- (X_l \odot Y_j)^T (Y_i + \mathbb{E}_{-s_{ijl}}\left[\frac{1}{\omega_{ii}}\right] \mathbb{E}_{-s_{ijl}} M_{-(i,j)}^{-s}) -->
<!-- \right]^2$ -->
<!-- \EndFor -->
<!-- \EndFor -->
<!-- \State $\zeta$: maximum value of expectation difference for parameters before and after updates. -->
<!-- \EndWhile -->
<!-- \end{algorithmic} -->
<!-- \end{algorithm} -->
<!-- $ -->
</div>
<div id="GraphRcompare" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">A.6</span> Overview of competing methods<a href="method.html#GraphRcompare" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here we only consider methods which allows for multiple graphical models or covariate-dependent graphs for individual. The GraphR model <a href="method.html#eq:graph-reg">(A.1)</a> estimates covariate-dependent graphs based on Gaussian likelihood with incorporation of discrete and/or continuous variables which encode heterogeneity of samples. Mean-field Variational Bayesian (MFVB) algorithm is implemented in the GraphR in order to achieve computational efficiency. The FGL, GGL <span class="citation">(<a href="#ref-danaher2014joint">Danaher, Wang, and Witten 2014</a>)</span> and LASICH <span class="citation">(<a href="#ref-saegusa2016joint">Saegusa and Shojaie 2016</a>)</span> can only be used in group-specific settings. The Gaussian graphical regression model proposed by <span class="citation">Zhang and Li (<a href="#ref-zhang2022high">2022</a>)</span> apply penalized likelihood functions for the inference which allows scenarios for both multiple graphical models and individual covariate-dependent graphs. However those methods fail to provide measurements of uncertainty and probabilistic reasoning. <span class="citation">Peterson, Stingo, and Vannucci (<a href="#ref-peterson2015bayesian">2015</a>)</span> propose a Bayesian model for multiple graphical models and implemented a MCMC based method. <span class="citation">Wang et al. (<a href="#ref-wang2021bayesian">2021</a>)</span> and <span class="citation">Ni, Stingo, and Baladandayuthapani (<a href="#ref-ni2019bayesian">2019</a>)</span> also develop methods to estimate conditional dependencies as a function of individual-level or group-level covariates in directed or undirected graphs. However both methods apply MCMC based algorithm and thus fail to scale with high dimensional data set. The Table below summerizes the comparison among these methods.</p>
<table>
<thead>
<tr>
<th>
</th>
<th>
Frequentist <br /> or <br /> Bayesian
</th>
<th>
Multiple graphical models
</th>
<th>
Covariate-dependent graphs
</th>
<th>
Scalability
</th>
<th>
Uncertainty quantification
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
GraphR
</th>
<th>
Bayesian
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
</tr>
<tr>
<th>
FGL, GGL <span class="citation">(<a href="#ref-danaher2014joint">Danaher, Wang, and Witten 2014</a>)</span>
</th>
<th>
Frequentist
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
</tr>
<tr>
<th>
LASICH <span class="citation">(<a href="#ref-saegusa2016joint">Saegusa and Shojaie 2016</a>)</span>
</th>
<th>
Frequentist
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
</tr>
<tr>
<th>
<span class="citation">Zhang and Li (<a href="#ref-zhang2022high">2022</a>)</span>
</th>
<th>
Frequentist
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
</tr>
<tr>
<th>
<span class="citation">Peterson, Stingo, and Vannucci (<a href="#ref-peterson2015bayesian">2015</a>)</span>
</th>
<th>
Bayesian
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
<th>
x
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
</tr>
<tr>
<th>
<span class="citation">Ni, Stingo, and Baladandayuthapani (<a href="#ref-ni2019bayesian">2019</a>)</span>
</th>
<th>
Bayesian
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
</tr>
<tr>
<th>
<span class="citation">Wang et al. (<a href="#ref-wang2021bayesian">2021</a>)</span>
</th>
<th>
Bayesian
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
<th>
x
</th>
<th>
<span class="math inline">\(\checkmark\)</span>
</th>
</tr>
</tbody>
<caption style="caption-side: bottom">
<span id="tab:differentmodeloverviewqsn4">Table A.1: </span> Methodological comparison among different methods.
</caption>
</table>
<!-- ### Frequentist Approaches -->
<!-- ### Bayesian Approaches -->

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-attias2000speech" class="csl-entry">
Attias, Hagai, John Platt, Alex Acero, and Li Deng. 2000. <span>“Speech Denoising and Dereverberation Using Probabilistic Models.”</span> <em>Advances in Neural Information Processing Systems</em> 13.
</div>
<div id="ref-danaher2014joint" class="csl-entry">
Danaher, Patrick, Pei Wang, and Daniela M Witten. 2014. <span>“The Joint Graphical Lasso for Inverse Covariance Estimation Across Multiple Classes.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 76 (2): 373–97.
</div>
<div id="ref-ni2019bayesian" class="csl-entry">
Ni, Yang, Francesco C Stingo, and Veerabhadran Baladandayuthapani. 2019. <span>“Bayesian <span>G</span>raphical <span>R</span>egression.”</span> <em>Journal of the American Statistical Association</em> 114 (525): 184–97.
</div>
<div id="ref-peterson2015bayesian" class="csl-entry">
Peterson, Christine, Francesco C Stingo, and Marina Vannucci. 2015. <span>“Bayesian Inference of Multiple Gaussian Graphical Models.”</span> <em>Journal of the American Statistical Association</em> 110 (509): 159–74.
</div>
<div id="ref-saegusa2016joint" class="csl-entry">
Saegusa, Takumi, and Ali Shojaie. 2016. <span>“Joint Estimation of Precision Matrices in Heterogeneous Populations.”</span> <em>Electronic Journal of Statistics</em> 10 (1): 1341.
</div>
<div id="ref-titsias2011spike" class="csl-entry">
Titsias, Michalis, and Miguel Lázaro-Gredilla. 2011. <span>“Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning.”</span> <em>Advances in Neural Information Processing Systems</em> 24.
</div>
<div id="ref-wang2021bayesian" class="csl-entry">
Wang, Zeya, Veerabhadran Baladandayuthapani, Ahmed O Kaseb, Hesham M Amin, Manal M Hassan, Wenyi Wang, and Jeffrey S Morris. 2021. <span>“Bayesian Edge Regression in Undirected Graphical Models to Characterize Interpatient Heterogeneity in Cancer.”</span> <em>Journal of the American Statistical Association</em>, no. just-accepted: 1–31.
</div>
<div id="ref-zhang2022high" class="csl-entry">
Zhang, Jingfei, and Yi Li. 2022. <span>“High-Dimensional Gaussian Graphical Regression Models with Covariates.”</span> <em>Journal of the American Statistical Association</em>, 1–13.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simulation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/01-Method-details.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
